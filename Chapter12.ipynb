{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十二章 pandas高级应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.1 分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "2     apple\n",
       "3     apple\n",
       "4     apple\n",
       "5    orange\n",
       "6     apple\n",
       "7     apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np; import pandas as pd\n",
    "values = pd.Series(['apple', 'orange', 'apple',\n",
    "                    'apple'] * 2)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'orange'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     6\n",
       "orange    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 许多数据系统（数据仓库、统计计算或其它应用）都发展出了特定的表征重复值的\n",
    "方法，以进行高效的存储和计算。在数据仓库中，最好的方法是使用所谓的包含不\n",
    "同值的维表(Dimension Table)，将主要的参数存储为引用维表整数键："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    1\n",
       "6    0\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = pd.Series([0, 1, 0, 0] * 2)\n",
    "dim = pd.Series(['apple', 'orange'])\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "0     apple\n",
       "0     apple\n",
       "0     apple\n",
       "1    orange\n",
       "0     apple\n",
       "0     apple\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim.take(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种用整数表示的方法称为分类或字典编码表示法。不同值得数组称为分类、字典\n",
    "或数据级。本书中，我们使用分类的说法。表示分类的整数值称为分类编码或简单\n",
    "地称为编码。\n",
    "分类表示可以在进行分析时大大的提高性能。你也可以在保持编码不变的情况下，\n",
    "对分类进行转换。一些相对简单的转变例子包括：\n",
    "- 重命名分类。\n",
    "- 加入一个新的分类，不改变已经存在的分类的顺序或位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas的分类类型\n",
    "pandas有一个特殊的分类类型astype('category')，用于保存使用整数分类表示法的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basket_id</th>\n",
       "      <th>count</th>\n",
       "      <th>fruit</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>apple</td>\n",
       "      <td>2.614279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>orange</td>\n",
       "      <td>2.990859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>apple</td>\n",
       "      <td>3.845227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.033553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.425778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>orange</td>\n",
       "      <td>1.194815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>apple</td>\n",
       "      <td>2.625645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>apple</td>\n",
       "      <td>3.239250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   basket_id  count   fruit    weight\n",
       "0          0      8   apple  2.614279\n",
       "1          1      5  orange  2.990859\n",
       "2          2      4   apple  3.845227\n",
       "3          3      9   apple  0.033553\n",
       "4          4      4   apple  0.425778\n",
       "5          5     14  orange  1.194815\n",
       "6          6     12   apple  2.625645\n",
       "7          7     14   apple  3.239250"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['apple', 'orange', 'apple', 'apple'] * 2\n",
    "N = len(fruits)\n",
    "df = pd.DataFrame({'fruit':fruits,'basket_id':np.arange(N),\n",
    "                  'count':np.random.randint(3,16,size=N),\n",
    "                  'weight':np.random.uniform(0,4,size=N)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     apple\n",
       "1    orange\n",
       "2     apple\n",
       "3     apple\n",
       "4     apple\n",
       "5    orange\n",
       "6     apple\n",
       "7     apple\n",
       "Name: fruit, dtype: category\n",
       "Categories (2, object): [apple, orange]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_cat = df['fruit'].astype('category')\n",
    "fruit_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fruit_cat的值不是NumPy数组，而是一个pandas.Categorical实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.arrays.categorical.Categorical"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = fruit_cat.values\n",
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apple', 'orange'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_accessors',\n",
       " '_can_hold_na',\n",
       " '_codes',\n",
       " '_codes_for_groupby',\n",
       " '_concat_same_type',\n",
       " '_constructor',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dtype',\n",
       " '_formatting_values',\n",
       " '_from_factorized',\n",
       " '_from_inferred_categories',\n",
       " '_from_sequence',\n",
       " '_get_codes',\n",
       " '_get_repr',\n",
       " '_maybe_coerce_indexer',\n",
       " '_ndarray_values',\n",
       " '_reduce',\n",
       " '_repr_categories',\n",
       " '_repr_categories_info',\n",
       " '_repr_footer',\n",
       " '_reset_cache',\n",
       " '_reverse_indexer',\n",
       " '_set_categories',\n",
       " '_set_codes',\n",
       " '_set_dtype',\n",
       " '_slice',\n",
       " '_tidy_repr',\n",
       " '_typ',\n",
       " '_values_for_argsort',\n",
       " '_values_for_factorize',\n",
       " '_values_for_rank',\n",
       " 'add_categories',\n",
       " 'argsort',\n",
       " 'as_ordered',\n",
       " 'as_unordered',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'categories',\n",
       " 'check_for_ordered',\n",
       " 'codes',\n",
       " 'copy',\n",
       " 'describe',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'equals',\n",
       " 'factorize',\n",
       " 'fillna',\n",
       " 'from_codes',\n",
       " 'get_values',\n",
       " 'is_dtype_equal',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'itemsize',\n",
       " 'map',\n",
       " 'max',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mode',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'ordered',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'remove_categories',\n",
       " 'remove_unused_categories',\n",
       " 'rename_categories',\n",
       " 'reorder_categories',\n",
       " 'repeat',\n",
       " 'searchsorted',\n",
       " 'set_categories',\n",
       " 'set_ordered',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'sort_values',\n",
       " 'take',\n",
       " 'take_nd',\n",
       " 'to_dense',\n",
       " 'tolist',\n",
       " 'unique',\n",
       " 'value_counts',\n",
       " 'view']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.Categorical从其它Python序列直接创建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[foo, bar, baz, foo, bar]\n",
       "Categories (3, object): [bar, baz, foo]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar'])\n",
    "my_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果已经从其它源获得了分类编码，你还可以使用from_codes构造器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[foo, bar, baz, foo, foo, bar]\n",
       "Categories (3, object): [foo, bar, baz]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['foo', 'bar', 'baz']\n",
    "codes = [0, 1, 2, 0, 0, 1]\n",
    "my_cats_2 = pd.Categorical.from_codes(codes=codes,categories=categories)\n",
    "my_cats_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与显示指定不同，分类变换不认定指定的分类顺序。因此取决于输入数据的顺序，\n",
    "categories数组的顺序会不同。当使用from_codes或其它的构造器时，你可以指\n",
    "定分类一个有意义的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[foo, bar, baz, foo, foo, bar]\n",
       "Categories (3, object): [foo < bar < baz]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_cat = pd.Categorical.from_codes(codes, categories,\n",
    "                                        ordered=True)\n",
    "ordered_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输出[foo < bar < baz]指明‘foo’位于‘bar’的前面，以此类推。无序的分类\n",
    "实例可以通过as_ordered排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[foo, bar, baz, foo, foo, bar]\n",
       "Categories (3, object): [foo < bar < baz]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cats_2.as_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用分类进行计算\n",
    "- 与非编码版本（比如字符串数组）相比，使用pandas的Categorical有些类似。\n",
    "- 某些pandas组件，比如groupby函数，更适合进行分类。还有一些函数可以使用有\n",
    "序标志位。\n",
    "- 来看一些随机的数值数据，使用pandas.qcut面元函数。它会返回pandas.Categorical，\n",
    "- 之前使用过pandas.cut，但没解释分类是如何工作的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2047,  0.4789, -0.5194, -0.5557,  1.9658])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "draws = np.random.randn(1000)\n",
    "draws[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.684, -0.0101], (-0.0101, 0.63], (-0.684, -0.0101], (-0.684, -0.0101], (0.63, 3.928], ..., (-0.0101, 0.63], (-0.684, -0.0101], (-2.9499999999999997, -0.684], (-0.0101, 0.63], (0.63, 3.928]]\n",
       "Length: 1000\n",
       "Categories (4, interval[float64]): [(-2.9499999999999997, -0.684] < (-0.684, -0.0101] < (-0.0101, 0.63] < (0.63, 3.928]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.qcut(draws,4)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.9499999999999997, -0.684]    250\n",
       "(-0.684, -0.0101]                250\n",
       "(-0.0101, 0.63]                  250\n",
       "(0.63, 3.928]                    250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 确切的样本分位数与分位的名称相比，不利于生成汇总。我们可以使用\n",
    "labels参数qcut，实现目的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Q2, Q3, Q2, Q2, Q4, ..., Q3, Q2, Q1, Q3, Q4]\n",
       "Length: 1000\n",
       "Categories (4, object): [Q1 < Q2 < Q3 < Q4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.qcut(draws,4,labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quartile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>250</td>\n",
       "      <td>-2.949343</td>\n",
       "      <td>-0.685484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>250</td>\n",
       "      <td>-0.683066</td>\n",
       "      <td>-0.010115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>250</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.628894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>3.927528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       min       max\n",
       "quartile                           \n",
       "Q1          250 -2.949343 -0.685484\n",
       "Q2          250 -0.683066 -0.010115\n",
       "Q3          250 -0.010032  0.628894\n",
       "Q4          250  0.634238  3.927528"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.Series(bins, name='quartile')\n",
    "results = (pd.Series(draws)\n",
    "           .groupby(bins)\n",
    "           .agg(['count', 'min', 'max']))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quartile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>250</td>\n",
       "      <td>-2.949343</td>\n",
       "      <td>-0.685484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>250</td>\n",
       "      <td>-0.683066</td>\n",
       "      <td>-0.010115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>250</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.628894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>3.927528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       min       max\n",
       "quartile                           \n",
       "Q1          250 -2.949343 -0.685484\n",
       "Q2          250 -0.683066 -0.010115\n",
       "Q3          250 -0.010032  0.628894\n",
       "Q4          250  0.634238  3.927528"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.Series(bins, name='quartile')\n",
    "results = (pd.Series(draws)\n",
    "           .groupby(bins)\n",
    "           .agg(['count', 'min', 'max']))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用分类提高性能\n",
    "一个特定数据集上做大量分析，将其转换为分类可以极大地提高效率。\n",
    "DataFrame列的分类使用的内存通常少的多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    baz\n",
       "0    foo\n",
       "0    foo\n",
       "1    bar\n",
       "2    baz\n",
       "1    bar\n",
       "2    baz\n",
       "2    baz\n",
       "1    bar\n",
       "1    bar\n",
       "    ... \n",
       "2    baz\n",
       "0    foo\n",
       "1    bar\n",
       "0    foo\n",
       "0    foo\n",
       "1    bar\n",
       "2    baz\n",
       "2    baz\n",
       "0    foo\n",
       "1    bar\n",
       "Length: 10000000, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10000000\n",
    "draws = pd.Series(np.random.randn(N))\n",
    "labels = pd.Series(['foo', 'bar', 'baz', 'qux']).take(np.random.randint(0,3,N))     \n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将标签转换为分类——1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[baz, foo, foo, bar, baz, ..., bar, baz, baz, foo, bar]\n",
       "Length: 10000000\n",
       "Categories (3, object): [bar, baz, foo]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.Categorical(labels)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将标签转换为分类——2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    baz\n",
       "0    foo\n",
       "0    foo\n",
       "1    bar\n",
       "2    baz\n",
       "dtype: category\n",
       "Categories (3, object): [bar, baz, foo]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = labels.astype('category')\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对比分类结果和labels的内存使用\n",
    "- 分类结果内存用的非常少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000104\n",
      "160000000\n",
      "10000104\n",
      "90000104\n"
     ]
    }
   ],
   "source": [
    "print(categories.memory_usage())\n",
    "print(labels.memory_usage())\n",
    "print(pd.Categorical(labels).memory_usage())\n",
    "print(labels.astype('category').memory_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 转换为分类不是没有代价的，但这是一次性的代价："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = labels.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "4    a\n",
       "5    b\n",
       "6    c\n",
       "7    d\n",
       "dtype: category\n",
       "Categories (4, object): [a, b, c, d]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['a', 'b', 'c', 'd'] * 2)\n",
    "cat_s = s.astype('category')\n",
    "cat_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cat属性提供了分类方法的入口："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    0\n",
       "5    1\n",
       "6    2\n",
       "7    3\n",
       "dtype: int8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_s.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_s.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假设我们知道这个数据的实际分类集，超出了数据中的四个值。我们可以使用\n",
    "set_categories方法改变它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "4    a\n",
       "5    b\n",
       "6    c\n",
       "7    d\n",
       "dtype: category\n",
       "Categories (5, object): [a, b, c, d, e]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_categories = ['a', 'b', 'c', 'd', 'e']\n",
    "cats_s2 = cat_s.cat.set_categories(actual_categories)\n",
    "cats_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 虽然数据看起来没变，新的分类将反映在它们的操作中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    2\n",
       "c    2\n",
       "b    2\n",
       "a    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    2\n",
       "c    2\n",
       "b    2\n",
       "a    2\n",
       "e    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_s2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在大数据集中，分类经常作为节省内存和高性能的便捷工具。过滤完大\n",
    "DataFrame或Series之后，许多分类可能不会出现在数据中。我们可以使用\n",
    "remove_unused_categories方法删除没看到的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "4    a\n",
       "5    b\n",
       "dtype: category\n",
       "Categories (4, object): [a, b, c, d]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_s3 = cat_s[cat_s.isin(['a','b'])]\n",
    "cats_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "4    a\n",
       "5    b\n",
       "dtype: category\n",
       "Categories (2, object): [a, b]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_s3.cat.remove_unused_categories()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为建模创建虚拟变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当使用统计或机器学习工具时，通常会将分类数据转换为虚拟变量，也称为\n",
    "one-hot编码。这包括创建一个不同类别的列的DataFrame；这些列包含给定分\n",
    "类的1s，其它为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Series in module pandas.core.series:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)\n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, dict, or scalar value\n",
      " |      Contains data stored in Series\n",
      " |  \n",
      " |      .. versionchanged :: 0.23.0\n",
      " |         If data is a dict, argument order is maintained for Python 3.6\n",
      " |         and later.\n",
      " |  \n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if not provided. If both a dict and index\n",
      " |      sequence are used, the index will override the keys found in the\n",
      " |      dict.\n",
      " |  dtype : numpy.dtype or None\n",
      " |      If None, dtype will be inferred\n",
      " |  copy : boolean, default False\n",
      " |      Copy input data\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right)\n",
      " |  \n",
      " |  __divmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __iand__ = f(self, other)\n",
      " |  \n",
      " |  __ifloordiv__ = f(self, other)\n",
      " |  \n",
      " |  __imod__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ior__ = f(self, other)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __ixor__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0 or 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0 or 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True if all elements within a series or along a Dataframe\n",
      " |      axis are non-zero, not-empty or not-False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.all : Return True if all elements are True\n",
      " |      pandas.DataFrame.any : Return True if one (or more) elements are True\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      \n",
      " |      DataFrames\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis.\n",
      " |      \n",
      " |      Unlike :meth:`DataFrame.all`, this performs an *or* operation. If any of the\n",
      " |      values along the specified axis is True, this will return True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.all : Return whether all elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Iteratively appending to a Series can be more computationally intensive\n",
      " |      than a single concatenate. A better solution is to append values to a\n",
      " |      list and then concatenate the list with the original Series all at\n",
      " |      once.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      Series.agg: only perform aggregating type operations\n",
      " |      Series.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      >>> series\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...     return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      " |          will be corrected to return the positional maximum in the future. Use\n",
      " |          'series.values.argmax' to get the position of the maximum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |         'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      " |          will be corrected to return the positional minimum in the future. Use\n",
      " |          'series.values.argmin' to get the position of the minimum now.\n",
      " |      \n",
      " |      \n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |      \n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary.\n",
      " |      right : scalar\n",
      " |          Right boundary.\n",
      " |      inclusive : bool, default True\n",
      " |          Include boundaries.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Each element will be a boolean.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.gt : Greater than of series and other\n",
      " |      pandas.Series.lt : Less than of series and other\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |      \n",
      " |      Boundary values are included by default:\n",
      " |      \n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      With `inclusive` set to ``False`` boundary values are excluded:\n",
      " |      \n",
      " |      >>> s.between(1, 4, inclusive=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      `left` and `right` can be any scalar value:\n",
      " |      \n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and return a scalar\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = Series([1, 2])\n",
      " |      >>> s2 = Series([0, 3])\n",
      " |      >>> s1.combine(s2, lambda x1, x2: x1 if x1 < x2 else x2)\n",
      " |      0    0\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series's values first\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform elementwise operation on two Series\n",
      " |          using a given function\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, *args, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : scalar or Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |      \n",
      " |      Equivalent to ``series divmod other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects. Can also be called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : 0, default 0\n",
      " |          Redundant for application on Series.\n",
      " |      index, columns : None\n",
      " |          Redundant for application on Series, but index can be used instead\n",
      " |          of labels.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : pandas.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A','B','C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop labels B en C\n",
      " |      \n",
      " |      >>> s.drop(labels=['B','C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      lama    speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      lama    speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      inplace : boolean, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : equivalent method on Index\n",
      " |      DataFrame.drop_duplicates : equivalent method on DataFrame\n",
      " |      Series.duplicated : related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an Series with duplicated entries.\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      2      lama\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |      \n",
      " |      >>> s.drop_duplicates()\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries. Setting the value of 'inplace' to ``True`` performs\n",
      " |      the operation inplace and returns ``None``.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep=False, inplace=True)\n",
      " |      >>> s\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return a new Series with missing values removed.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          There is only one axis to drop values from.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      **kwargs\n",
      " |          Not in use.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Drop NA values from a Series.\n",
      " |      \n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Keep the Series with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> ser.dropna(inplace=True)\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |      \n",
      " |      >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Indicate duplicate Series values.\n",
      " |      \n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      which is equivalent to\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.series.Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Index.duplicated : Equivalent method on pandas.Index\n",
      " |      pandas.DataFrame.duplicated : Equivalent method on pandas.DataFrame\n",
      " |      pandas.Series.drop_duplicates : Remove duplicate values from Series\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      expanding : Provides expanding transformations.\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      `**kwds` : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Check whether `values` are contained in Series.\n",
      " |      \n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |            Support for values as a set.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin : equivalent method on DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'lama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['lama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : alias of isna\n",
      " |      Series.notna : boolean inverse of isna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (a dict, Series, or\n",
      " |      function).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          Same index as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Map inputs to outputs (both of type `Series`):\n",
      " |      \n",
      " |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      " |      >>> x\n",
      " |      one      1\n",
      " |      two      2\n",
      " |      three    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      " |      >>> y\n",
      " |      1    foo\n",
      " |      2    bar\n",
      " |      3    baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      If `arg` is a dictionary, return a new Series with values converted\n",
      " |      according to the dictionary's mapping:\n",
      " |      \n",
      " |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      " |      \n",
      " |      >>> x.map(z)\n",
      " |      one   A\n",
      " |      two   B\n",
      " |      three C\n",
      " |      \n",
      " |      Use na_action to control whether NA values are affected by the mapping\n",
      " |      function.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      " |      \n",
      " |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3    this is a string nan\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3                     NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When `arg` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``:\n",
      " |      \n",
      " |      >>> from collections import Counter\n",
      " |      >>> counter = Counter()\n",
      " |      >>> counter['bar'] += 1\n",
      " |      >>> y.map(counter)\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of the Series.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      104\n",
      " |      \n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |      \n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |      \n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      96\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      212\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the *integer* indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatibility with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 3, 0, 4], index=['a', 'b', 'c', 'd'])\n",
      " |      # same return although index of s is different\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      b    3\n",
      " |      d    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : alias of notna\n",
      " |      Series.isna : boolean inverse of notna\n",
      " |      Series.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Returns the difference between the maximum value and the\n",
      " |                  minimum value in the object. This is the equivalent of the\n",
      " |                  ``numpy.ndarray`` method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      Applies the `put` method to its `values` attribute\n",
      " |      if it has one.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      index : array-like, optional (should be specified using keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use ``Series.reindex`` instead.\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter Series index labels or name\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, hashable sequence, dict-like or function, optional\n",
      " |          dict-like or functions are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis : where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, *args, **kwargs)\n",
      " |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `repeats` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the Series are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values\n",
      " |      Series.where : Replace values based on boolean condition\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$':'new', 'foo':'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the pecularities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |      \n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |      \n",
      " |      Generate a DataFrame with default index.\n",
      " |      \n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |      \n",
      " |      To specify the name of the new column use `name`.\n",
      " |      \n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |      \n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |      \n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      To update the Series in place, without generating a new one\n",
      " |      set `inplace` to True. Note that it also requires ``drop=True``.\n",
      " |      \n",
      " |      >>> s.reset_index(inplace=True, drop=True)\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |      \n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |      \n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |      \n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |      \n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |      \n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int\n",
      " |          Number of decimal places to round to (default: 0).\n",
      " |          If decimals is negative, it specifies the number of\n",
      " |          positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      DataFrame.round\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread',\n",
      " |                              'cheese', 'milk'], ordered=True)\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained,\n",
      " |      a new object is created with the label placed at the end of the result\n",
      " |      index.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Please use .at[] or .iat[] accessors.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0 or 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      " |      Sort Series by index labels.\n",
      " |      \n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          Axis to direct sorting. This can only be 0 for Series.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool, default true\n",
      " |          Sort ascending vs. descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information.  'mergesort' is the only stable algorithm. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The original Series sorted by the labels\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value\n",
      " |      Series.sort_values : Sort Series by the value\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Inplace\n",
      " |      \n",
      " |      >>> s.sort_index(inplace=True)\n",
      " |      >>> s\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Specify index level to sort\n",
      " |      \n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |      \n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values.\n",
      " |      \n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          Axis to direct sorting. The value 'index' is accepted for\n",
      " |          compatibility with DataFrame.sort_values.\n",
      " |      ascending : bool, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' is the only stable  algorithm.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series ordered by values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values ascending order (default behaviour)\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values descending order\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values inplace\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False, inplace=True)\n",
      " |      >>> s\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values putting NAs first\n",
      " |      \n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort a series of strings\n",
      " |      \n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order),\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Use :meth:`Series.sort_index`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, compression=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      compression : string, optional\n",
      " |          A string representing the compression to use in the output file.\n",
      " |          Allowed values are 'gzip', 'bz2', 'zip', 'xz'. This input is only\n",
      " |          used when the first argument is a filename.\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self, into=<class 'dict'>)\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.Mapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : collections.Mapping\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(dd)\n",
      " |      defaultdict(<type 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      " |      Write Series to an excel sheet\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or Categorical\n",
      " |          The unique values returned as a NumPy array. In case of categorical\n",
      " |          data type, returned as a Categorical.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.unique : top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      An unordered Categorical will return categories in the order of\n",
      " |      appearance.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [b, a, c]\n",
      " |      \n",
      " |      An ordered Categorical preserves the category ordering.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [a < b < c]\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  valid(self, inplace=False, **kwargs)\n",
      " |      Return Series without null values.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`Series.dropna` instead.\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |      Create a new view of the Series.\n",
      " |      \n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n",
      " |      >>> s\n",
      " |      0   -2\n",
      " |      1   -1\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    2\n",
      " |      dtype: int8\n",
      " |      \n",
      " |      The 8 bit signed integer representation of `-1` is `0b11111111`, but\n",
      " |      the same bytes represent 255 if read as an 8 bit unsigned integer:\n",
      " |      \n",
      " |      >>> us = s.view('uint8')\n",
      " |      >>> us\n",
      " |      0    254\n",
      " |      1    255\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: uint8\n",
      " |      \n",
      " |      The views share the same underlying values:\n",
      " |      \n",
      " |      >>> us[0] = 128\n",
      " |      >>> s\n",
      " |      0   -128\n",
      " |      1     -1\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: int8\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      " |      Construct Series from array.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |          Use pd.Series(..) constructor instead.\n",
      " |  \n",
      " |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use :func:`pandas.read_csv` instead.\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  asobject\n",
      " |      Return object Series which contains boxed values.\n",
      " |      \n",
      " |      .. deprecated :: 0.23.0\n",
      " |      \n",
      " |         Use ``astype(object)`` instead.\n",
      " |      \n",
      " |      *this is an internal non-public method*\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |      Accessor object for datetimelike properties of the Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.dt.hour\n",
      " |      >>> s.dt.second\n",
      " |      >>> s.dt.quarter\n",
      " |      \n",
      " |      Returns a Series indexed like the original Series.\n",
      " |      Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |      \n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort `uniques` and shuffle `labels` to maintain the\n",
      " |          relationship.\n",
      " |      \n",
      " |      na_sentinel : int, default -1\n",
      " |          Value to mark \"not found\".\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(labels)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |      \n",
      " |          .. note ::\n",
      " |      \n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.cut : Discretize continuous-valued array.\n",
      " |      pandas.unique : Find the unique valuse in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `labels` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
      " |      >>> labels\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      Missing values are indicated in `labels` with `na_sentinel`\n",
      " |      (``-1`` by default). Note that missing values are never\n",
      " |      included in `uniques`.\n",
      " |      \n",
      " |      >>> labels, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
      " |      >>> labels\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |      \n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      [a, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, desipite not being\n",
      " |      present in ``cat.values``.\n",
      " |      \n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |      \n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> labels, uniques = pd.factorize(cat)\n",
      " |      >>> labels\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |      return if I have any nans; enables various perf speedups\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_unique : boolean\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : calculate the absolute value element-wise.\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`DataFrame.values` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True.\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : raise on invalid input\n",
      " |          .. deprecated:: 0.20.0\n",
      " |             Use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1,2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip_lower : Clip values below specified threshold(s).\n",
      " |      clip_upper : Clip values above specified threshold(s).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of the input with values below a threshold truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : numeric or array-like\n",
      " |          Minimum value allowed. All values below threshold will be set to\n",
      " |          this value.\n",
      " |      \n",
      " |          * float : every value is compared to `threshold`.\n",
      " |          * array-like : The shape of `threshold` should match the object\n",
      " |            it's compared to. When `self` is a Series, `threshold` should be\n",
      " |            the length. When `self` is a DataFrame, `threshold` should 2-D\n",
      " |            and the same shape as `self` for ``axis=None``, or 1-D and the\n",
      " |            same length as the axis being compared.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Align `self` with `threshold` along the given axis.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Return copy of input with values below and above\n",
      " |          thresholds truncated.\n",
      " |      Series.clip_upper : Return copy of input with values above\n",
      " |          threshold truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series single threshold clipping:\n",
      " |      \n",
      " |      >>> s = pd.Series([5, 6, 7, 8, 9])\n",
      " |      >>> s.clip_lower(8)\n",
      " |      0    8\n",
      " |      1    8\n",
      " |      2    8\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Series clipping element-wise using an array of thresholds. `threshold`\n",
      " |      should be the same length as the Series.\n",
      " |      \n",
      " |      >>> elemwise_thresholds = [4, 8, 7, 2, 5]\n",
      " |      >>> s.clip_lower(elemwise_thresholds)\n",
      " |      0    5\n",
      " |      1    8\n",
      " |      2    7\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      DataFrames can be compared to a scalar.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(3)\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      Or to an array of values. By default, `threshold` should be the same\n",
      " |      shape as the DataFrame.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([[3, 4], [2, 2], [6, 2]]))\n",
      " |         A  B\n",
      " |      0  3  4\n",
      " |      1  3  4\n",
      " |      2  6  6\n",
      " |      \n",
      " |      Control how `threshold` is broadcast with `axis`. In this case\n",
      " |      `threshold` should be the same length as the axis specified by\n",
      " |      `axis`.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([3, 3, 5]), axis='index')\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([4, 5]), axis='columns')\n",
      " |         A  B\n",
      " |      0  4  5\n",
      " |      1  4  5\n",
      " |      2  5  6\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series, DataFrame or Panel\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return counts of unique dtypes in this object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dtypes : Return the dtypes in this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_dtype_counts()\n",
      " |      float64    1\n",
      " |      int64      1\n",
      " |      object     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return counts of unique ftypes in this object.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |      \n",
      " |      This is useful for SparseDataFrame or for DataFrames containing\n",
      " |      sparse arrays.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each type and\n",
      " |          sparsity (dense/sparse)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ftypes : Return ftypes (indication of sparse/dense and dtype) in\n",
      " |          this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_ftype_counts()\n",
      " |      float64:dense    1\n",
      " |      int64:dense      1\n",
      " |      object:dense     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted a (single) key.\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      observed : boolean, default False\n",
      " |          This only applies if any of the groupers are Categoricals\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj_head : type of caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |  \n",
      " |  infer_objects(self)\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to numeric typeR\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |      limit_area : {'inside', 'outside'}, default None\n",
      " |          * None: (default) no fill restriction\n",
      " |          * 'inside' Only fill NaNs surrounded by valid values (interpolate).\n",
      " |          * 'outside' Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is False and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : iterable, optional\n",
      " |          positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Column label to be popped\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      popped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches. Can be list-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter the name of the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set as the axis name attribute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : boolean, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      " |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      " |      deprecated and will be removed in a future version. Use ``rename``\n",
      " |      instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename : Alter Series index labels or name\n",
      " |      pandas.DataFrame.rename : Alter DataFrame index labels or name\n",
      " |      pandas.Index.rename : Set new names on index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.rename_axis(\"foo\")\n",
      " |      foo\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      \n",
      " |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      " |      bar  A  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |          For PeriodIndex only, controls whether to use the start or end of\n",
      " |          `rule`\n",
      " |      kind: {'timestamp', 'period'}, optional\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          ``DateTimeIndex`` or 'period' to convert it to a ``PeriodIndex``.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |                                                      freq='A',\n",
      " |                                                      periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      \n",
      " |      Resample by month using 'start' `convention`. Values are assigned to\n",
      " |      the first month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='start').asfreq().head()\n",
      " |      2012-01    1.0\n",
      " |      2012-02    NaN\n",
      " |      2012-03    NaN\n",
      " |      2012-04    NaN\n",
      " |      2012-05    NaN\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      Resample by month using 'end' `convention`. Values are assigned to\n",
      " |      the last month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='end').asfreq()\n",
      " |      2012-12    1.0\n",
      " |      2013-01    NaN\n",
      " |      2013-02    NaN\n",
      " |      2013-03    NaN\n",
      " |      2013-04    NaN\n",
      " |      2013-05    NaN\n",
      " |      2013-06    NaN\n",
      " |      2013-07    NaN\n",
      " |      2013-08    NaN\n",
      " |      2013-09    NaN\n",
      " |      2013-10    NaN\n",
      " |      2013-11    NaN\n",
      " |      2013-12    2.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |      \n",
      " |      You can use `random state` for reproducibility:\n",
      " |      \n",
      " |      >>> df.sample(random_state=1)\n",
      " |      A         B         C         D\n",
      " |      37 -2.027662  0.103611  0.237496 -0.165867\n",
      " |      43 -0.259323 -0.583426  1.516140 -0.479118\n",
      " |      12 -1.686325 -0.579510  0.985195 -0.460286\n",
      " |      8   1.167946  0.429082  1.215742 -1.636041\n",
      " |      9   1.197475 -0.864188  1.554031 -1.505264\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use df.loc[df.index.map(crit)] to select via labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=None)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : boolean, default None\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             ``inplace=None`` currently falls back to to True, but in a\n",
      " |             future version, will default to False. Use inplace=True\n",
      " |             explicitly rather than relying on the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The original object is not modified.\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index', inplace=False)\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns', inplace=False)\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          - True, use the provided separator, writing in a csv format for\n",
      " |            allowing easy pasting into excel.\n",
      " |          - False, write a string representation of the object to the\n",
      " |            clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `gtk` or `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      format : {'fixed', 'table'}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      data_columns :  list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum.\n",
      " |      dropna : bool, default False\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None, index=True)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : string\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - 'split' : dict like {'index' -> [index],\n",
      " |              'columns' -> [columns], 'data' -> [values]}\n",
      " |            - 'records' : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - 'index' : dict like {index -> {column -> value}}\n",
      " |            - 'columns' : dict like {column -> {index -> value}}\n",
      " |            - 'values' : just the values array\n",
      " |            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : boolean, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      compression : {None, 'gzip', 'bz2', 'zip', 'xz'}\n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer', protocol=4)\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values for this parameter depend on the version of Python. For\n",
      " |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      " |          valid value. For Python >= 3.4, 4 is a valid value. A negative\n",
      " |          value for the protocol parameter is equivalent to setting its value\n",
      " |          to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects.\n",
      " |      schema : string, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Rows will be written in batches of this size at a time. By default,\n",
      " |          all rows will be written at once.\n",
      " |      dtype : dict, optional\n",
      " |          Specifying the datatype for columns. The keys should be the column\n",
      " |          names and the values should be the SQLAlchemy types or strings for\n",
      " |          the sqlite3 legacy mode.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_sql : read a DataFrame from a table\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, string, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, string, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : boolean, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                    index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is True and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      Series.at : Access a single value using a label\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          When label does not exist in DataFrame\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  is_copy\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n",
      " |      favor of the more strict .iloc and .loc indexers.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierarchical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s)\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError:\n",
      " |          when any items are not found\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_s = pd.Series(['a','b','c','d']*2, dtype=\"category\")\n",
    "help(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas.get_dummies函数可以转换这个分类数据为包含虚\n",
    "拟变量的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d\n",
       "0  1  0  0  0\n",
       "1  0  1  0  0\n",
       "2  0  0  1  0\n",
       "3  0  0  0  1\n",
       "4  1  0  0  0\n",
       "5  0  1  0  0\n",
       "6  0  0  1  0\n",
       "7  0  0  0  1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(cat_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2 GroupBy高级应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分组转换和“解封”GroupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在分组操作中学习了apply方法，进行转换。还有另一个\n",
    "transform方法，它与apply很像，但是对使用的函数有一定限制：\n",
    "- 它可以产生向分组形状广播标量值\n",
    "- 它可以产生一个和输入组形状相同的对象\n",
    "- 它不能修改输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  value\n",
       "0    a    0.0\n",
       "1    b    1.0\n",
       "2    c    2.0\n",
       "3    a    3.0\n",
       "4    b    4.0\n",
       "5    c    5.0\n",
       "6    a    6.0\n",
       "7    b    7.0\n",
       "8    c    8.0\n",
       "9    a    9.0\n",
       "10   b   10.0\n",
       "11   c   11.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'key': ['a', 'b', 'c'] * 4,\n",
    "                   'value': np.arange(12.)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     value\n",
       "key       \n",
       "a      4.5\n",
       "b      5.5\n",
       "c      6.5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.groupby('key')\n",
    "\n",
    "print(type(g.mean()))\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "key\n",
       "a    4.5\n",
       "b    5.5\n",
       "c    6.5\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.groupby('key')['value']\n",
    "print(type(g.mean()))\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key\n",
       "a    4.5\n",
       "b    5.5\n",
       "c    6.5\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.groupby('key').value\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假设我们想产生一个和df['value']形状相同的Series，但值替换为按键分组的平均\n",
    "值。我们可以传递函数lambda x: x.mean()进行转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.5\n",
       "1     5.5\n",
       "2     6.5\n",
       "3     4.5\n",
       "4     5.5\n",
       "5     6.5\n",
       "6     4.5\n",
       "7     5.5\n",
       "8     6.5\n",
       "9     4.5\n",
       "10    5.5\n",
       "11    6.5\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.transform(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于内置的聚合函数，我们可以传递一个字符串假名作为GroupBy的agg方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.5\n",
       "1     5.5\n",
       "2     6.5\n",
       "3     4.5\n",
       "4     5.5\n",
       "5     6.5\n",
       "6     4.5\n",
       "7     5.5\n",
       "8     6.5\n",
       "9     4.5\n",
       "10    5.5\n",
       "11    6.5\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      2.0\n",
       "2      4.0\n",
       "3      6.0\n",
       "4      8.0\n",
       "5     10.0\n",
       "6     12.0\n",
       "7     14.0\n",
       "8     16.0\n",
       "9     18.0\n",
       "10    20.0\n",
       "11    22.0\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.transform(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      2.0\n",
       "2      3.0\n",
       "3      4.0\n",
       "4      5.0\n",
       "5      6.0\n",
       "6      7.0\n",
       "7      8.0\n",
       "8      9.0\n",
       "9     10.0\n",
       "10    11.0\n",
       "11    12.0\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.transform(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__bytes__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_accessors', '_add_numeric_operations', '_agg_doc', '_aggregate', '_aggregate_multiple_funcs', '_aggregate_named', '_apply_filter', '_apply_to_column_groupbys', '_apply_whitelist', '_assure_grouper', '_bool_agg', '_builtin_table', '_concat_objects', '_constructor', '_cumcount_array', '_cython_agg_general', '_cython_table', '_cython_transform', '_def_str', '_deprecations', '_dir_additions', '_dir_deletions', '_fill', '_get_cythonized_result', '_get_index', '_get_indices', '_gotitem', '_group_selection', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cython_func', '_iterate_slices', '_make_wrapper', '_obj_with_exclusions', '_python_agg_general', '_python_apply_general', '_reset_cache', '_reset_group_selection', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_group_selection', '_set_result_index_ordered', '_shallow_copy', '_transform_fast', '_transform_should_cast', '_try_aggregate_string_function', '_try_cast', '_wrap_aggregated_output', '_wrap_applied_output', '_wrap_output', '_wrap_transformed_output', 'agg', 'aggregate', 'all', 'any', 'apply', 'backfill', 'bfill', 'corr', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtype', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'last', 'mad', 'max', 'mean', 'median', 'min', 'ndim', 'ngroup', 'ngroups', 'nlargest', 'nsmallest', 'nth', 'nunique', 'ohlc', 'pad', 'pct_change', 'pipe', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sem', 'shift', 'size', 'skew', 'std', 'sum', 'tail', 'take', 'transform', 'tshift', 'unique', 'value_counts', 'var']\n"
     ]
    }
   ],
   "source": [
    "print(dir(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key\n",
       "a    0.0\n",
       "b    1.0\n",
       "c    2.0\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SeriesGroupBy in module pandas.core.groupby.groupby object:\n",
      "\n",
      "class SeriesGroupBy(GroupBy)\n",
      " |  Class for grouping and aggregating relational data. See aggregate,\n",
      " |  transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SeriesGroupBy\n",
      " |      GroupBy\n",
      " |      _GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, func_or_funcs, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func_or_funcs, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).min()\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg('min')\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby.apply\n",
      " |      pandas.Series.groupby.transform\n",
      " |      pandas.Series.aggregate\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function ``func``  group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to ``apply`` must take a series as its first\n",
      " |      argument and return a dataframe, a series or a scalar. ``apply`` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. ``apply`` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While ``apply`` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods.\n",
      " |      Pandas offers a wide range of method that will be much faster\n",
      " |      than using ``apply`` for their specific purposes, so try to use them\n",
      " |      before reaching for ``apply``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          A callable that takes a series as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to ``func``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the current implementation ``apply`` calls func twice on the\n",
      " |      first group to decide whether it can take a fast or slow code\n",
      " |      path. This can lead to unexpected behavior if func has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> ser = pd.Series([0, 1, 2], index='a a b'.split())\n",
      " |      >>> g = ser.groupby(ser.index)\n",
      " |      \n",
      " |      From ``ser`` above we can see that ``g`` has two groups, ``a``, ``b``.\n",
      " |      Calling ``apply`` in various ways, we can get different grouping results:\n",
      " |      \n",
      " |      Example 1: The function passed to ``apply`` takes a series as\n",
      " |      its argument and returns a series.  ``apply`` combines the result for\n",
      " |      each group together into a new series:\n",
      " |      \n",
      " |      >>> g.apply(lambda x:  x*2 if x.name == 'b' else x/2)\n",
      " |      0    0.0\n",
      " |      1    0.5\n",
      " |      2    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Example 2: The function passed to ``apply`` takes a series as\n",
      " |      its argument and returns a scalar. ``apply`` combines the result for\n",
      " |      each group together into a series, including setting the index as\n",
      " |      appropriate:\n",
      " |      \n",
      " |      >>> g.apply(lambda x: x.max() - x.min())\n",
      " |      a    1\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate, transform\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a Series excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          To apply to each group. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)\n",
      " |      1    2\n",
      " |      3    4\n",
      " |      5    6\n",
      " |      Name: B, dtype: int64\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : Series\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Returns number of unique elements in the group\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None)\n",
      " |      Calculate percent change of each value to previous entry in group\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed Series on each group and\n",
      " |      return a Series having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, f returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Same shape\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                          'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      # Broadcastable\n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  corr\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  cov\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  diff\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  hist\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      `**kwds` : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywors have no effect but might be accepted\n",
      " |          for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A' ,'B' ,'C' ,'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  mad\n",
      " |      \n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  nlargest\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nsmallest\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  quantile\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  skew\n",
      " |      \n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  unique\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or Categorical\n",
      " |          The unique values returned as a NumPy array. In case of categorical\n",
      " |          data type, returned as a Categorical.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.unique : top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      array([Timestamp('2016-01-01 00:00:00-0500', tz='US/Eastern')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      An unordered Categorical will return categories in the order of\n",
      " |      appearance.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [b, a, c]\n",
      " |      \n",
      " |      An ordered Categorical preserves the category ordering.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [a < b < c]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from GroupBy:\n",
      " |  \n",
      " |  all(self, skipna=True)\n",
      " |      Returns True if all values in the group are truthful, else False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  any(self, skipna=True)\n",
      " |      Returns True if any value in the group is truthful, else False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.backfill\n",
      " |      DataFrame.backfill\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.backfill\n",
      " |      DataFrame.backfill\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pad\n",
      " |      DataFrame.pad\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  first(self, **kwargs)\n",
      " |      Compute first of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  last(self, **kwargs)\n",
      " |      Compute last of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max(self, **kwargs)\n",
      " |      Compute max of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  median(self, **kwargs)\n",
      " |      Compute median of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min(self, **kwargs)\n",
      " |      Compute min of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ngroup(self, ascending=True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying ``dropna`` allows count ignoring NaN\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying ``as_index=False`` in ``groupby`` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values\n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pad\n",
      " |      DataFrame.pad\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  prod(self, **kwargs)\n",
      " |      Compute prod of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)\n",
      " |      Provides the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      pct : boolean, default False\n",
      " |          Compute percentage rank of data within each group\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |      Returns\n",
      " |      -----\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper\n",
      " |      Return a new grouper with our resampler appended\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling\n",
      " |      functionality per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift each group by periods observations\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum(self, **kwargs)\n",
      " |      Compute sum of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : type of obj\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply a function ``func`` with arguments to this GroupBy object and return\n",
      " |      the function's result.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Use ``.pipe`` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, string)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a ``(callable, data_keyword)`` tuple where ``data_keyword`` is a\n",
      " |          string indicating the keyword of ``callable`` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             positional arguments passed into ``func``.\n",
      " |      kwargs : dict, optional\n",
      " |               a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.pipe : Apply a function with arguments to a series\n",
      " |      pandas.DataFrame.pipe: Apply a function with arguments to a dataframe\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      dict {group name -> group labels}\n",
      " |  \n",
      " |  indices\n",
      " |      dict {group name -> group indices}\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1.161895\n",
       "1    -1.161895\n",
       "2    -1.161895\n",
       "3    -0.387298\n",
       "4    -0.387298\n",
       "5    -0.387298\n",
       "6     0.387298\n",
       "7     0.387298\n",
       "8     0.387298\n",
       "9     1.161895\n",
       "10    1.161895\n",
       "11    1.161895\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.transform(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1.161895\n",
       "1    -1.161895\n",
       "2    -1.161895\n",
       "3    -0.387298\n",
       "4    -0.387298\n",
       "5    -0.387298\n",
       "6     0.387298\n",
       "7     0.387298\n",
       "8     0.387298\n",
       "9     1.161895\n",
       "10    1.161895\n",
       "11    1.161895\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  value\n",
       "0    a    0.0\n",
       "1    b    1.0\n",
       "2    c    2.0\n",
       "3    a    3.0\n",
       "4    b    4.0\n",
       "5    c    5.0\n",
       "6    a    6.0\n",
       "7    b    7.0\n",
       "8    c    8.0\n",
       "9    a    9.0\n",
       "10   b   10.0\n",
       "11   c   11.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分组的时间重采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-20 00:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-20 00:02:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-20 00:03:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-20 00:04:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-05-20 00:05:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-05-20 00:06:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-05-20 00:07:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-05-20 00:08:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-05-20 00:09:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-05-20 00:10:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-05-20 00:11:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-05-20 00:12:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-05-20 00:13:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-05-20 00:14:00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  value\n",
       "0  2017-05-20 00:00:00      0\n",
       "1  2017-05-20 00:01:00      1\n",
       "2  2017-05-20 00:02:00      2\n",
       "3  2017-05-20 00:03:00      3\n",
       "4  2017-05-20 00:04:00      4\n",
       "5  2017-05-20 00:05:00      5\n",
       "6  2017-05-20 00:06:00      6\n",
       "7  2017-05-20 00:07:00      7\n",
       "8  2017-05-20 00:08:00      8\n",
       "9  2017-05-20 00:09:00      9\n",
       "10 2017-05-20 00:10:00     10\n",
       "11 2017-05-20 00:11:00     11\n",
       "12 2017-05-20 00:12:00     12\n",
       "13 2017-05-20 00:13:00     13\n",
       "14 2017-05-20 00:14:00     14"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 15\n",
    "times = pd.date_range('2017-05-20 00:00', freq='1min', periods=N)\n",
    "df = pd.DataFrame({'time':times,\n",
    "                  'value': np.arange(N)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:00:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:10:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "time                      \n",
       "2017-05-20 00:00:00      5\n",
       "2017-05-20 00:05:00      5\n",
       "2017-05-20 00:10:00      5"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用time做为索引\n",
    "df.set_index('time').resample('5min').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2017-05-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2017-05-20 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2017-05-20 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>2017-05-20 00:01:00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2017-05-20 00:01:00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "      <td>2017-05-20 00:01:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>2017-05-20 00:02:00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key                time  value\n",
       "0   a 2017-05-20 00:00:00    0.0\n",
       "1   b 2017-05-20 00:00:00    1.0\n",
       "2   c 2017-05-20 00:00:00    2.0\n",
       "3   a 2017-05-20 00:01:00    3.0\n",
       "4   b 2017-05-20 00:01:00    4.0\n",
       "5   c 2017-05-20 00:01:00    5.0\n",
       "6   a 2017-05-20 00:02:00    6.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.tile(a,(y,x)) 序列a沿y方向复制y次，沿x方向复制x次\n",
    "df2 = pd.DataFrame({'time': times.repeat(3),\n",
    "                    'key': np.tile(['a', 'b', 'c'], N),\n",
    "                    'value': np.arange(N * 3.)})\n",
    "df2[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 要对每个key值进行相同的重采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 引入 pd.TimeGrouper对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">a</th>\n",
       "      <th>2017-05-20 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:01:00</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:02:00</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:03:00</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:04:00</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:06:00</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:07:00</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:08:00</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:09:00</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">c</th>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:06:00</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:07:00</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:08:00</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:09:00</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:10:00</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:11:00</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:12:00</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:13:00</th>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:14:00</th>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         value\n",
       "key time                      \n",
       "a   2017-05-20 00:00:00    0.0\n",
       "    2017-05-20 00:01:00    3.0\n",
       "    2017-05-20 00:02:00    6.0\n",
       "    2017-05-20 00:03:00    9.0\n",
       "    2017-05-20 00:04:00   12.0\n",
       "    2017-05-20 00:05:00   15.0\n",
       "    2017-05-20 00:06:00   18.0\n",
       "    2017-05-20 00:07:00   21.0\n",
       "    2017-05-20 00:08:00   24.0\n",
       "    2017-05-20 00:09:00   27.0\n",
       "...                        ...\n",
       "c   2017-05-20 00:05:00   17.0\n",
       "    2017-05-20 00:06:00   20.0\n",
       "    2017-05-20 00:07:00   23.0\n",
       "    2017-05-20 00:08:00   26.0\n",
       "    2017-05-20 00:09:00   29.0\n",
       "    2017-05-20 00:10:00   32.0\n",
       "    2017-05-20 00:11:00   35.0\n",
       "    2017-05-20 00:12:00   38.0\n",
       "    2017-05-20 00:13:00   41.0\n",
       "    2017-05-20 00:14:00   44.0\n",
       "\n",
       "[45 rows x 1 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_key = pd.TimeGrouper('5min')\n",
    "resampled = (df2.set_index('time').groupby(['key','time']).sum())\n",
    "resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">a</th>\n",
       "      <th>2017-05-20 00:00:00</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:10:00</th>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">b</th>\n",
       "      <th>2017-05-20 00:00:00</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:10:00</th>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">c</th>\n",
       "      <th>2017-05-20 00:00:00</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:05:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-20 00:10:00</th>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         value\n",
       "key time                      \n",
       "a   2017-05-20 00:00:00   30.0\n",
       "    2017-05-20 00:05:00  105.0\n",
       "    2017-05-20 00:10:00  180.0\n",
       "b   2017-05-20 00:00:00   35.0\n",
       "    2017-05-20 00:05:00  110.0\n",
       "    2017-05-20 00:10:00  185.0\n",
       "c   2017-05-20 00:00:00   40.0\n",
       "    2017-05-20 00:05:00  115.0\n",
       "    2017-05-20 00:10:00  190.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled = (df2.set_index('time').groupby(['key',time_key]).sum())\n",
    "resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3 链式编程技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
